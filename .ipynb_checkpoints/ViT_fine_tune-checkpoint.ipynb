{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5222bd4d-6dde-40c2-bf5d-9fd1814927fc",
   "metadata": {},
   "source": [
    "# Fine Tuning / Transfer learning of ViT model\n",
    "Use case: classifier Lego/Duplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73771b80-f5ad-4514-b451-62f744d0f62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 12:43:33.888779: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-25 12:43:33.932101: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-25 12:43:33.932135: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-25 12:43:33.933612: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-25 12:43:33.940467: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-25 12:43:33.941225: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-25 12:43:34.830795: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import imageio.v2 as iio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow.keras as ks\n",
    "from transformers import ViTImageProcessor, TFViTForImageClassification, TFViTModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e1baf3-0743-4f21-850d-8310278d4b09",
   "metadata": {},
   "source": [
    "## Load pretrained model and corresponding ImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d27b526-0c84-4add-a3c8-17d695d8f8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFViTModel.\n",
      "\n",
      "All the weights of TFViTModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of ViTImageProcessor and use ViT base model as pretrained model\n",
    "feature_extractor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "# Create an instance of ViTForImageClassification and use ViT base model as pretrained model\n",
    "ViT_base_model = TFViTModel.from_pretrained('google/vit-base-patch16-224-in21k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57633e1-4521-4e93-b70f-064552ef188b",
   "metadata": {},
   "source": [
    "## Sublcass of keras.Model\n",
    "Create a model class containing the  pretrained ViT and a dense classifier on top of pooler layer of ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f69d8a-0b99-4c7f-8afc-c7b5dbce2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViTLegoDuplo(tf.keras.Model):\n",
    "    '''Class is intended to be constructed on a ViT model containing a pooler layer.\n",
    "    A dense layer is added on top of the ViT pooler. In case of a use as a binary classifier, \n",
    "    the outputs will be logits from one neuron. In case of a one-hot-encoded classification\n",
    "    task, the output will be probabilities from a Softmax-function. See __init__() for details.\n",
    "\n",
    "    A method is provided to declare different layersr of the ViT model as trainable (see\n",
    "    \".choose_trainables()\"\" for details).\n",
    "    '''\n",
    "    def __init__(self, vit_base_model, no_classes='binary'):\n",
    "        # vit_base_model should be a ViT model with pretrained pooler layer\n",
    "        # no_classes: Pass \"binary\" to obtain a single neuron output, providing logits\n",
    "        #     Pass: integer number of classes for one-hot-encoded data, layer provides\n",
    "        #     probabilties from Softmax-function in this case\n",
    "        super().__init__()\n",
    "        self.vit = vit_base_model\n",
    "        if no_classes == 'binary':\n",
    "            self.dense_layer = tf.keras.layers.Dense(1, activation='tanh')\n",
    "        else:\n",
    "            self.dense_layer = tf.keras.layers.Dense(no_classes, activation='tanh')\n",
    "            self.dense_layer = tf.keras.layers.Softmax()\n",
    "\n",
    "    def choose_trainables(self, embeddings=True, encoder=True, layernorm=True, pooler=True):\n",
    "        # Method to set trainable argument of components of ViT model.\n",
    "        \n",
    "        # Access embedding layer of ViT model in its mainlayer and set trainable parameter\n",
    "        self.vit.layers[0].embeddings.trainable = embeddings\n",
    "        # Access encoder layers of ViT model in its mainlayer and set trainable parameter\n",
    "        self.vit.layers[0].encoder.trainable = encoder\n",
    "        # Access layer normalization of ViT model in its mainlayer and set trainable parameter\n",
    "        self.vit.layers[0].layernorm.trainable = layernorm\n",
    "        # Access pooler of ViT model in its mainlayer and set trainable parameter\n",
    "        self.vit.layers[0].pooler.trainable = pooler\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.vit(x)[1] # take only output of pooler\n",
    "        return self.dense_layer(x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d086e26b-abc7-4235-a736-412ba0875930",
   "metadata": {},
   "source": [
    "## Instantiate model for Lego/Duplo problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d9e8bc-d6b6-4eac-82ba-2d531921f42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vi_t_lego_duplo\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  769       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 86390017 (329.55 MB)\n",
      "Trainable params: 769 (3.00 KB)\n",
      "Non-trainable params: 86389248 (329.55 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate model from ViTLegoDuplo class and define trainable argument for components of ViT model\n",
    "classifier = ViTLegoDuplo(ViT_base_model) # for binary classification\n",
    "classifier.choose_trainables(embeddings=False, encoder=False, layernorm=False, pooler=False)    \n",
    "# Define appropriate loss, compile and build model.\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "classifier.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "classifier.build(input_shape=(None, 3, 224, 224))\n",
    "classifier.summary(expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6d60a3-7437-42f5-9954-306bc52b2ac6",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "From pictures in directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10c5f539-308e-480d-bd07-b3fecb3eaf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of directories with data to use in training, validation and testing\n",
    "# One directory per class\n",
    "datadir_list = [\n",
    "    '/home/felbus/transformers/data/Lego', \n",
    "    '/home/felbus/transformers/data/Duplo'\n",
    "]\n",
    "\n",
    "# Definition of useful classes and functions for later Papeline creation\n",
    "\n",
    "class ParseCat:\n",
    "    '''Class helps to transform string labels to integer numbers. Therefore an initially\n",
    "    empty dictionary is filled with an pair (categry_str: #), when class is called. \n",
    "    # is the integer representation of a category string value and is generated automatically,\n",
    "    when class is called with an unknown category string value. Class returns # uppon call.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.cat_dict = {} # emtpy dictionary to hold ('category': #) pairs\n",
    "\n",
    "    def __call__(self, category):\n",
    "        # Dynamically define #, if category is unkwown, return #\n",
    "        if (cat_int := self.cat_dict.get(category)) is None: \n",
    "            self.cat_dict[category] = cat_int = len(self.cat_dict)\n",
    "        return cat_int # return #\n",
    "\n",
    "    def __str__(self):\n",
    "        # Generate human readable output for print()\n",
    "        content_str = f'#\\t\\tCategory\\n-------------------------------------\\n'\n",
    "        for i, (key, value) in enumerate(self.cat_dict.items()):\n",
    "            content_str += f'{value}\\t\\t{key}\\n'\n",
    "        return content_str\n",
    "        \n",
    "\n",
    "@tf.py_function(Tout=tf.float32)\n",
    "def apply_feature_extractor(x):\n",
    "    '''Function will apply \"feature_extractor\" to image data. Decorator allows usage of this function inside tf.data.Dataset.map().\n",
    "    Parameters:\n",
    "    x <tf.Tensor>: image data\n",
    "\n",
    "    Return:\n",
    "    <tf.Tensor>: features of image data with shape (channels, heigth, width)\n",
    "    '''\n",
    "    return feature_extractor.preprocess(images=x, return_tensors='tf')['pixel_values']\n",
    "\n",
    "def list_file_generator(dir_list):\n",
    "    '''Generator function will take a list with directory paths and yield tuples\n",
    "    of two strings (filepath, label). Label will be extracted from lowest part of\n",
    "    directory path and is pared to an integer category number.\n",
    "    Parameters:\n",
    "    dir_list <list <str>>: list of strings containing paths to directories\n",
    "\n",
    "    Return:\n",
    "    <tuple (<str>, <int>): Tuple containing absolute file path and label category\n",
    "    '''\n",
    "    # Loop over all directories passed in dir_list\n",
    "    for directory in dir_list:\n",
    "        # Decode bytestring to string\n",
    "        directory = directory.decode('utf-8')\n",
    "        # Take lowest directory name as label and parse it to integer\n",
    "        _, label_str = os.path.split(directory)\n",
    "        label = lego_parse(label_str)\n",
    "        # Create list of all files in directory and loop over these files\n",
    "        file_list = os.listdir(directory)\n",
    "        for file in file_list:\n",
    "            # join path and filename to absolute file path of this file\n",
    "            file_path = os.path.join(directory, file)\n",
    "            # yield tupel (absolute file path to image file, label)\n",
    "            yield file_path, label\n",
    "            \n",
    "def load_image_data(path):\n",
    "    '''Function will load image data and process it with tensorflow decode_image function.\n",
    "    Parameters:\n",
    "    path <str>: file path string to load the image from\n",
    "\n",
    "    Return:\n",
    "    <tf.Tensor>: Decoded image with shape (height, width, channels)\n",
    "    '''\n",
    "    image = tf.io.read_file(path)\n",
    "    return tf.io.decode_image(image, channels=3)\n",
    "\n",
    "# Creation of Pipeline object tf.data.Dataset\n",
    "\n",
    "# Instantiate a perser object for label management\n",
    "lego_parse = ParseCat()\n",
    "\n",
    "# Initiate an tf.data.Dataset instance from generator function. \n",
    "# Elements will be of type tuple with two Tensors (file path and integer label)\n",
    "image_dataset = tf.data.Dataset.from_generator(\n",
    "    list_file_generator, args=[datadir_list], output_signature=(\n",
    "        tf.TensorSpec(shape=(), dtype=tf.string), # file path\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int16) # label category\n",
    "    )\n",
    ")\n",
    "\n",
    "# Load image data by mapping file path to load_image_data function\n",
    "image_dataset = image_dataset.map(lambda x, y: (load_image_data(x), y))\n",
    "\n",
    "# Wrap call of ViTImageProcessor in batch() / unbatch(), because otherwise it will add a dimension, that is not\n",
    "# recognized as a batching dimension by the tf.data.Dataset instance.\n",
    "image_dataset = image_dataset.batch(2)\n",
    "# Apply feature_extractor to all image data, data in pipeline will be \"channel dimension first\"\n",
    "# Images will be rescaled to [0, 1] and then normalized to means [0.5, 0.5, 0.5], resized to 3x224x224\n",
    "image_dataset = image_dataset.map(lambda x, y: (apply_feature_extractor(x), y))\n",
    "image_dataset = image_dataset.unbatch()\n",
    "\n",
    "# Create new dataset from iterator over image_dataset. This is a work-around, as the\n",
    "# return of ViTImageProcessor somehow returns a Dataset, that is unsuitable to be \n",
    "# passed to Model. Most probably because of missing Tensor Shape information\n",
    "image_dataset = tf.data.Dataset.from_generator(\n",
    "    image_dataset.__iter__, output_signature=(\n",
    "        tf.TensorSpec(shape=(3, 224, 224), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int16)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Batching \n",
    "image_dataset = image_dataset.batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d9ac7-2668-454a-a432-f6f94a129fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
